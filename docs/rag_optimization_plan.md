# RAG å„ªåŒ–è¨ˆç•« v2.0ï¼ˆå¤šæ¨¡æ…‹å„ªå…ˆï¼‰

## ç•¶å‰æ¶æ§‹ç¸½è¦½

### æ”¯æ´çš„æª”æ¡ˆæ ¼å¼ âœ…
å·²å¯¦ä½œçš„ Loadersï¼š
- âœ… **PDF** ([`pdf_loader.py`](file:///home/monica/Cook.ai/backend/app/services/document_loader/pdf_loader.py)) - pdfplumber + OCR
- âœ… **PPTX** ([`pptx_loader.py`](file:///home/monica/Cook.ai/backend/app/services/document_loader/pptx_loader.py)) - python-pptx + OCR
- âœ… **DOCX** ([`docx_loader.py`](file:///home/monica/Cook.ai/backend/app/services/document_loader/docx_loader.py))
- âœ… **TXT** ([`txt_loader.py`](file:///home/monica/Cook.ai/backend/app/services/document_loader/txt_loader.py))
- âœ… **Image** ([`image_loader.py`](file:///home/monica/Cook.ai/backend/app/services/document_loader/image_loader.py)) - jpg/png/gif/bmp/tiff/webp
- âœ… **Web** ([`web_loader.py`](file:///home/monica/Cook.ai/backend/app/services/document_loader/web_loader.py))
- âœ… **Google Drive** ([`google_drive_loader.py`](file:///home/monica/Cook.ai/backend/app/services/document_loader/google_drive_loader.py))

### å¤šæ¨¡æ…‹è³‡æ–™çµæ§‹

**Page.structured_elements æ ¼å¼**ï¼š
```python
[
    {
                parts.append("[åœ–ç‰‡]")
    return " ".join(parts).strip()
```

---

## å„ªåŒ–è¨ˆç•«ï¼ˆæŒ‰æ‚¨å»ºè­°çš„é †åºï¼‰

### ğŸ¯ **Phase 1: æ“´å……æª”æ¡ˆæ ¼å¼æ”¯æ´**

#### ç›®æ¨™
ç¢ºä¿æ‰€æœ‰ loader éƒ½å·²æ•´åˆåˆ° ingestion pipeline

#### æª¢æŸ¥æ¸…å–®

| Loader | å·²å¯¦ä½œ | å·²æ•´åˆ | æ¸¬è©¦ç‹€æ…‹ |
|--------|-------|-------|---------|
| PDF | âœ… | âœ… | âœ… |
| PPTX | âœ… | âœ… | âœ… |
| DOCX | âœ… | â“ | â“ |
| TXT | âœ… | â“ | â“ |
| Image | âœ… | â“ | â“ |
| Web | âœ… | â“ | â“ |
| Google Drive | âœ… | â“ | â“ |

#### å¯¦ä½œæ­¥é©Ÿ

1. **æ¸¬è©¦æ‰€æœ‰ loaders**
   ```python
   # backend/tests/test_all_loaders.py
   
   def test_docx_loader():
       loader = get_loader("sample.docx")
       doc = loader.load("test_files/sample.docx")
       assert len(doc.pages) > 0
       assert doc.pages[0].structured_elements
   
   def test_image_loader():
       loader = get_loader("sample.png")
       doc = loader.load("test_files/sample.png")
       # ç¢ºèª OCR æœ‰é‹ä½œ
       assert doc.pages[0].structured_elements[0].get("ocr_text")
   ```

2. **ä¿®å¾©ä»»ä½•å•é¡Œ**
   - DOCX/Web/Google Drive æ˜¯å¦ç¼ºå°‘ `structured_elements`ï¼Ÿ
   - ç¢ºä¿æ‰€æœ‰ loader è¿”å›çµ±ä¸€æ ¼å¼

3. **åœ¨ `ingestion.py` ä¸­æ¸¬è©¦**
   ```bash
   python -m backend.app.agents.teacher_agent.ingestion
   # æ¸¬è©¦å„ç¨®æª”æ¡ˆæ ¼å¼
   ```

---

### ğŸ¯ **Phase 2: å„ªåŒ– OCR èˆ‡æ–‡å­—è½‰éŒ„**

#### ç•¶å‰ OCR è¨­å®š
```python
# ocr_utils.py:15
pytesseract.image_to_string(image, lang='chi_tra+eng')
```

#### å„ªåŒ–æ–¹å‘

##### 2.1 æ”¹ç”¨æ›´æº–ç¢ºçš„ OCR å¼•æ“

**é¸é … Aï¼šPaddleOCR**ï¼ˆæ¨è–¦ï¼Œä¸­æ–‡è¾¨è­˜æ›´ä½³ï¼‰
```python
# backend/app/services/document_loader/ocr_utils.py

from paddleocr import PaddleOCR

# åˆå§‹åŒ–ï¼ˆå…¨åŸŸå–®ä¾‹ï¼‰
ocr_engine = PaddleOCR(use_angle_cls=True, lang='ch', use_gpu=False)

def ocr_image_to_text_paddle(image_bytes: bytes) -> str:
    """ä½¿ç”¨ PaddleOCR è¾¨è­˜åœ–ç‰‡æ–‡å­—"""
    try:
        image = Image.open(io.BytesIO(image_bytes))
        result = ocr_engine.ocr(np.array(image), cls=True)
        
        # æå–æ–‡å­—
        texts = []
        for line in result[0]:
            texts.append(line[1][0])  # æ¯ä¸€è¡Œçš„æ–‡å­—
        
        return "\n".join(texts)
    except Exception as e:
        print(f"PaddleOCR error: {e}")
        # Fallback to Tesseract
        return ocr_image_to_text_tesseract(image_bytes)
```

**é¸é … Bï¼šAzure/Google Vision API**ï¼ˆä»˜è²»ï¼Œæœ€æº–ç¢ºï¼‰
```python
from google.cloud import vision

client = vision.ImageAnnotatorClient()

def ocr_image_to_text_google(image_bytes: bytes) -> str:
    image = vision.Image(content=image_bytes)
    response = client.text_detection(image=image)
    return response.full_text_annotation.text
```

##### 2.2 åœ–ç‰‡å‰è™•ç†ï¼ˆæå‡ OCR æº–ç¢ºåº¦ï¼‰

```python
def preprocess_image_for_ocr(image_bytes: bytes) -> bytes:
    """
    OCR å‰è™•ç†ï¼šç°éšã€å»å™ªã€äºŒå€¼åŒ–
    """
    import cv2
    import numpy as np
    
    # è¼‰å…¥åœ–ç‰‡
    nparr = np.frombuffer(image_bytes, np.uint8)
    img = cv2.imdecode(nparr, cv2.IMREAD_COLOR)
    
    # 1. è½‰ç°éš
    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
    
    # 2. å»å™ª
    denoised = cv2.fastNlMeansDenoising(gray)
    
    # 3. äºŒå€¼åŒ–ï¼ˆé–¾å€¼è‡ªå‹•èª¿æ•´ï¼‰
    binary = cv2.adaptiveThreshold(
        denoised, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, 
        cv2.THRESH_BINARY, 11, 2
    )
    
    # è½‰å› bytes
    _, buffer = cv2.imencode('.png', binary)
    return buffer.tobytes()
```

##### 2.3 OCR éŒ¯èª¤ä¿®æ­£

```python
import re

OCR_CORRECTION_DICT = {
    r'PREROCESSING': 'PREPROCESSING',
    r'DEATIE\s+DIEANIN': '',
    r'DATO': 'DATA',
    r'(\d)\s+(\d)': r'\1\2',  # ä¿®æ­£æ•¸å­—é–“å¤šé¤˜ç©ºæ ¼
}

def post_process_ocr_text(text: str) -> str:
    """OCR å¾Œè™•ç†ï¼šä¿®æ­£å¸¸è¦‹éŒ¯èª¤"""
    for pattern, repl in OCR_CORRECTION_DICT.items():
        text = re.sub(pattern, repl, text, flags=re.IGNORECASE)
    return text.strip()
```

---

### ğŸ¯ **Phase 3: è³‡æ–™æ¸…ç†ï¼ˆä¿ç•™ base64ï¼‰** â­â­â­â­â­ æœ€é—œéµ

> [!IMPORTANT]
> **Phase 1 èˆ‡ Phase 3 åˆä½µå¯¦ä½œ**
> 
> åŸå› ï¼šéœ€è¦å…ˆçµ±ä¸€ loader æ ¼å¼ï¼ˆPhase 1ï¼‰ï¼Œæ‰èƒ½æ­£ç¢ºæ¸…ç†èˆ‡ä¿ç•™å¤šæ¨¡æ…‹è³‡æ–™ï¼ˆPhase 3ï¼‰

#### æ ¸å¿ƒè¨­è¨ˆï¼šé›™è»Œè³‡æ–™å„²å­˜

**ç›®æ¨™**ï¼š
- âœ… **Chunk æ–‡å­—** (`chunk_text`): ç”¨æ–¼ text embedding å’Œæª¢ç´¢
- âœ… **Multimodal metadata** (`multimodal_metadata`): ä¿ç•™ base64 ä¾›å¤šæ¨¡æ…‹ LLM ä½¿ç”¨

#### è³‡æ–™åº«æ¶æ§‹ç†è§£

| è¡¨å | å„²å­˜å±¤ç´š | è³‡æ–™å…§å®¹ | ç”¨é€” |
|------|----------|----------|------|
| **document_content** | Page | `structured_content` (å®Œæ•´ base64) | ä¾› Generator ä½¿ç”¨å®Œæ•´é é¢è³‡æ–™ |
| **document_chunks** | Chunk | `chunk_text` (æ–‡å­—+OCR) + `embedding` + **`multimodal_metadata`** (æ–°å¢) | å‘é‡æª¢ç´¢ + åœ–ç‰‡è³‡è¨Šä¿ç•™ |

#### å¯¦ä½œæª¢æŸ¥æ¸…å–®

##### 3.1 è³‡æ–™åº«æº–å‚™
- [ ] å»ºç«‹ migration script: `migrations/add_multimodal_metadata.sql`
  ```sql
  ALTER TABLE document_chunks ADD COLUMN multimodal_metadata JSONB;
  CREATE INDEX idx_chunks_multimodal ON document_chunks USING GIN (multimodal_metadata);
  ```
- [ ] åŸ·è¡Œè³‡æ–™åº« migration
- [ ] é©—è­‰æ¬„ä½æ–°å¢æˆåŠŸ

##### 3.2 çµ±ä¸€ Document Loaders
- [ ] ä¿®æ”¹ `__init__.py` - ç°¡åŒ– Page dataclass
  - ç§»é™¤ `native_text`, `extracted_images`, `generated_text_for_chunking`
  - åªä¿ç•™ `page_number` å’Œ `structured_elements`
  - ç§»é™¤ `ExtractedImage` dataclass
- [ ] ä¿®æ”¹ PPTX Loader - ä½¿ç”¨ `structured_elements`
- [ ] ä¿®æ”¹ DOCX Loader - ä½¿ç”¨ `structured_elements`
- [ ] ä¿®æ”¹ TXT Loader - ä½¿ç”¨ `structured_elements`
- [ ] ä¿®æ”¹ Image Loader - ä½¿ç”¨ `structured_elements`
- [ ] ä¿®æ”¹ Web Loader - å®Œå…¨é‡æ§‹ä½¿ç”¨ `structured_elements` + OCR
- [ ] å„ªåŒ– PDF Loader - ç°¡åŒ– `top` æ¬„ä½è™•ç†

**çµ±ä¸€æ ¼å¼**:
```python
structured_elements = [
    {"type": "text", "content": "æ®µè½æ–‡å­—..."},
    {"type": "image", "base64": "data:image/png;base64,...", "ocr_text": "..."},
]
```

##### 3.3 Ingestion Pipeline æ”¹é€ 

**åˆªé™¤èˆŠå‡½æ•¸**:
- [ ] åˆªé™¤ `_generate_human_text_from_structured_content` (line 29-44)
  - **èˆŠåŠŸèƒ½**: åªæå–æ–‡å­—å’Œ OCRï¼Œä¸Ÿæ£„ base64
  - **å•é¡Œ**: ç„¡æ¸…ç†ã€ç„¡å¤šæ¨¡æ…‹ä¿ç•™

**å¯¦ä½œæ–°å‡½æ•¸**:
- [ ] å¯¦ä½œ `_clean_and_prepare_multimodal_content`
  - **æ–°åŠŸèƒ½**: æ¸…ç† + ä¿ç•™ base64 + è¿”å›é›™è»Œè³‡æ–™
  - **è¿”å›**: `(text_for_chunking, multimodal_metadata)`
  
- [ ] å¯¦ä½œ `_is_code_block` - ç¨‹å¼ç¢¼æª¢æ¸¬
  - æª¢æ¸¬ `import`, `def`, `class` ç­‰é—œéµå­—
  - éæ¿¾ç¨‹å¼ç¢¼å€å¡Šï¼Œä¸ç´å…¥ chunk
  
- [ ] å¯¦ä½œ `_clean_text` - æ–‡å­—æ¸…ç†
  - ç§»é™¤é ç¢¼ï¼ˆå–®ç¨çš„æ•¸å­—è¡Œï¼‰
  - ç§»é™¤æ•™å¸«è³‡è¨Š
  - æ¨™æº–åŒ–ç©ºç™½ç¬¦è™Ÿ
  
- [ ] å¯¦ä½œ `_post_process_ocr` - OCR å¾Œè™•ç†
  - ç§»é™¤ OCR å™ªéŸ³å­—å…ƒ
  - ä¿®æ­£æ•¸å­—é–“å¤šé¤˜ç©ºæ ¼

**ä¿®æ”¹ ingestion æµç¨‹**:
- [ ] ä¿®æ”¹ Task 4 (Save Document Content) - ä½¿ç”¨æ–°çš„æ¸…ç†å‡½æ•¸
  ```python
  text_for_chunking, mm_metadata = _clean_and_prepare_multimodal_content(
      page.structured_elements
  )
  page.text_for_chunking = text_for_chunking
  page.multimodal_metadata = mm_metadata
  ```

- [ ] ä¿®æ”¹ Task 6 (Generate Embeddings) - å„²å­˜ `multimodal_metadata`
  ```python
  chunk_data = [{
      "chunk_text": text,
      "metadata": meta,
      "multimodal_metadata": mm_meta,  # âœ… æ–°å¢
      "embedding": embedding
  }...]
  ```

##### 3.4 Text Splitter å‡ç´š

- [ ] ä¿®æ”¹ `chunk_document` å‡½æ•¸ç°½å
  - è¿”å›ä¸‰å…ƒçµ„: `(chunk_text, page_metadata, multimodal_metadata)`
  
- [ ] å¯¦ä½œå­—å…ƒåˆ°åœ–ç‰‡çš„æ˜ å°„é‚è¼¯
  - å»ºç«‹ `char_to_image_map` è¿½è¹¤åœ–ç‰‡ä½ç½®
  
- [ ] å¯¦ä½œ chunk-level åœ–ç‰‡åˆ†é…
  - æ ¹æ“š chunk çš„å­—å…ƒç¯„åœï¼Œåˆ†é…å±¬æ–¼è©² chunk çš„åœ–ç‰‡
  - æ§‹å»ºæ¯å€‹ chunk çš„ `multimodal_metadata`

##### 3.5 RAG Agent æ•´åˆ

- [ ] ä¿®æ”¹ `rag_agent.py` - search() æ–¹æ³•
  ```python
  SELECT id, chunk_text, metadata, multimodal_metadata  -- âœ… æ–°å¢
  FROM document_chunks
  ```

- [ ] ä¿®æ”¹è¿”å›æ ¼å¼
  ```python
  found_text_chunks.append({
      "chunk_id": chunk_id,
      "text": chunk_text,
      "source_pages": page_numbers,
      "multimodal_metadata": mm_meta  # âœ… æ–°å¢
  })
  ```

#### multimodal_metadata æ ¼å¼

```json
{
  "images": [
    {
      "position": 0,
      "base64": "data:image/png;base64,...",
      "ocr_text": "å„ªé»ï¼šæ˜“æ–¼å¯¦ä½œã€è¨ˆç®—é€Ÿåº¦å¿«"
    }
  ],
  "contains_code": false
}
```

#### è³‡æ–™æµç¨‹

```
Loader â†’ structured_elements (text + image base64)
    â†“
_clean_and_prepare_multimodal_content()
    â†“
â”œâ”€ text_for_chunking: "æ–‡å­— + [åœ–ç‰‡å…§å®¹: æ¸…ç†å¾Œçš„OCR]"
â””â”€ multimodal_metadata: {"images": [{"base64": "...", "ocr_text": "..."}]}
    â†“
document_content.structured_content âœ… ä¿ç•™å®Œæ•´ base64
document_chunks.chunk_text + multimodal_metadata âœ… é›™è»Œå„²å­˜
    â†“
RAG æª¢ç´¢ â†’ text_chunks (å« multimodal_metadata)
         â†’ page_content (å«å®Œæ•´ structured_elements)
    â†“
Generator: ä½¿ç”¨ page_content (å®Œæ•´ base64) â†’ GPT-4V çœ‹åœ–
Ragas: ä½¿ç”¨ text_chunks.text (ç´”æ–‡å­—+OCR) â†’ æ–‡å­—æ¯”å°
```

---

#### é©—è­‰æª¢æŸ¥æ¸…å–®

- [ ] æ¸¬è©¦æ‰€æœ‰ 7 ç¨®æª”æ¡ˆæ ¼å¼ ingest (PDF, PPTX, DOCX, TXT, PNG, Web, Google Drive)
- [ ] é©—è­‰ `document_content.structured_content` ä¿ç•™å®Œæ•´ base64
- [ ] é©—è­‰ `document_chunks.multimodal_metadata` æ­£ç¢ºå„²å­˜
- [ ] é©—è­‰ `chunk_text` ä¹¾æ·¨ï¼ˆç„¡ç¨‹å¼ç¢¼ã€ç„¡é ç¢¼ã€OCR å·²æ¸…ç†ï¼‰
- [ ] ç«¯åˆ°ç«¯ RAG æµç¨‹æ¸¬è©¦

**SQL é©—è­‰ç¯„ä¾‹**:
```sql
-- æª¢æŸ¥ document_content
SELECT structured_content -> 0 FROM document_content LIMIT 1;
-- é æœŸ: {"type": "image", "base64": "data:image/png;base64,...", "ocr_text": "..."}

-- æª¢æŸ¥ document_chunks
SELECT multimodal_metadata FROM document_chunks LIMIT 1;
-- é æœŸ: {"images": [...], "contains_code": false}
```

---

### ğŸ¯ **Phase 0: Debug API å»ºç«‹** â­â­â­â­â­ï¼ˆç•¶å‰å„ªå…ˆï¼‰

#### ç›®æ¨™
å»ºç«‹å°ˆé–€çš„ Debug API ä¾†å¯è¦–åŒ–å’Œé©—è­‰å¤šæ¨¡æ…‹ RAG ç³»çµ±

#### èƒŒæ™¯
- Vision LLM å·²æ•´åˆï¼ˆ12/17 å®Œæˆï¼‰
- multimodal_metadata å·²åŠ å…¥ ingestion pipeline
- éœ€è¦å·¥å…·ä¾†é©—è­‰æ•´å€‹æµç¨‹æ˜¯å¦æ­£ç¢ºé‹ä½œ

#### å¯¦ä½œå…§å®¹

##### 0.1 å‰µå»º RAG Debug Router

**æ–°å¢æª”æ¡ˆ**: `backend/app/routers/rag_debug_router.py`

**ç«¯é» 1: `/debug/rag_retrieval`**
- åŠŸèƒ½: æ¸¬è©¦ RAG æª¢ç´¢æµç¨‹
- è¿”å›:
  - åŸå§‹ `chunks`ï¼ˆå« `multimodal_metadata`ï¼‰
  - åŸå§‹ `page_content`ï¼ˆå®Œæ•´çµæ§‹åŒ–å…§å®¹ï¼‰
  - LLM è¼¸å…¥æ ¼å¼ï¼ˆtext + base64 imagesï¼‰
  - äººé¡å¯è®€æ ¼å¼ï¼ˆç´”æ–‡å­—ï¼‰
  - åŸ·è¡Œæ™‚é–“çµ±è¨ˆ

**ç«¯é» 2: `/debug/rag_full_pipeline`**
- åŠŸèƒ½: å®Œæ•´ RAG æµç¨‹æ¸¬è©¦ï¼ˆæª¢ç´¢ + ç”Ÿæˆ + Ragas æº–å‚™ï¼‰
- è¿”å›:
  - æª¢ç´¢çµæœ
  - LLM ç”Ÿæˆç­”æ¡ˆï¼ˆä½¿ç”¨ base64 åœ–ç‰‡ï¼‰
  - Ragas è©•ä¼°è¼¸å…¥ï¼ˆç´”æ–‡å­—ï¼‰
  - åŸ·è¡Œæ™‚é–“çµ±è¨ˆ

##### 0.2 é—œéµè¨­è¨ˆåŸå‰‡

**è³‡æ–™åˆ†é›¢ç­–ç•¥**:
```
RAG æª¢ç´¢
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ chunks          â”‚ page_content       â”‚
â”‚ (è¼•é‡æ–‡å­—)       â”‚ (å®Œæ•´çµæ§‹åŒ–å…§å®¹)    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â†“                    â†“
    çµ¦ Ragas         çµ¦ LLM (_prepare_multimodal_content)
    (ç´”æ–‡å­—)         (æå– base64 + æ–‡å­—)
```

**LLM å¤šæ¨¡æ…‹æ”¯æ´** âœ…:
- æ¨¡å‹: `gpt-4o-mini` / `gpt-4o`
- å‡½æ•¸: `_prepare_multimodal_content()` (exam_nodes.py Line 97-127)
- è¼¸å…¥: `page_content` â†’ è¼¸å‡º: (text, [base64_images])

##### 0.3 é©—è­‰ç›®æ¨™

- [ ] Vision LLM æè¿°å‡ºç¾åœ¨ `chunks[].text` ä¸­
- [ ] `multimodal_metadata` æ­£ç¢ºå„²å­˜åœ¨è³‡æ–™åº«
- [ ] LLM ç¢ºå¯¦æ¥æ”¶åˆ° base64 åœ–ç‰‡
- [ ] Ragas åªæ¥æ”¶ç´”æ–‡å­—ï¼ˆä¸å« base64ï¼‰
- [ ] åŸ·è¡Œæ™‚é–“åˆç†ï¼ˆæª¢ç´¢ < 200msï¼Œå®Œæ•´æµç¨‹ < 5sï¼‰

##### 0.4 å·¥ä½œé‡èˆ‡æ™‚ç¨‹

- **å¯¦ä½œæ™‚é–“**: 1-1.5 å°æ™‚
- **æ¸¬è©¦æ™‚é–“**: 30 åˆ†é˜
- **é æœŸå®Œæˆ**: ç•¶æ—¥

---

### ğŸ¯ **Phase 4: èªç¾©é‚Šç•Œåˆ‡åˆ†**

#### 4.1 æŒ‰æ®µè½åˆ‡åˆ†

```python
def semantic_chunk_by_paragraphs(
    pages: List[Page],
    max_chunk_size: int = 1000,
    min_chunk_size: int = 200
) -> List[Tuple[str, Dict, Dict]]:
    """
    åŸºæ–¼æ®µè½çš„èªç¾©åˆ‡åˆ†
    """
    chunks = []
    
    for page in pages:
        # æå–æ–‡å­—å…ƒç´ 
        text_elements = [
            e for e in page.structured_elements 
            if e["type"] == "text"
        ]
        
        # åˆä½µå°æ®µè½
        paragraphs = []
        current_para = ""
        
        for elem in text_elements:
            content = elem["content"]
            
            # æ®µè½çµæŸæ¨™è¨˜ï¼šæ›è¡Œæˆ–å¥è™Ÿ
            if content.endswith(('\n', 'ã€‚', 'ï¼', 'ï¼Ÿ')):
                current_para += content
                paragraphs.append(current_para.strip())
                current_para = ""
            else:
                current_para += content + " "
        
        if current_para:
            paragraphs.append(current_para.strip())
        
        # çµ„åˆæ®µè½æˆ chunks
        current_chunk_elements = []
        current_length = 0
        
        for para in paragraphs:
            if current_length + len(para) > max_chunk_size:
                # ç•¶å‰ chunk å®Œæˆ
                if current_length >= min_chunk_size:
                    text, mm_meta = clean_and_structure_chunk(
                        "\n\n".join(current_chunk_elements),
                        page.structured_elements,
                        0, 0  # éœ€èª¿æ•´ç‚ºå¯¦éš›ç¯„åœ
                    )
                    chunks.append((
                        text,
                        {"page_numbers": [page.page_number]},
                        mm_meta
                    ))
                
                current_chunk_elements = [para]
                current_length = len(para)
            else:
                current_chunk_elements.append(para)
                current_length += len(para)
        
        # æœ€å¾Œä¸€å€‹ chunk
        if current_chunk_elements and current_length >= min_chunk_size:
            text, mm_meta = clean_and_structure_chunk(...)
            chunks.append((text, {...}, mm_meta))
    
    return chunks
```

---

### ğŸ¯ **Phase 5: æª¢ç´¢å„ªåŒ–**

#### 5.1 Hybrid Searchï¼ˆå‘é‡ + é—œéµå­—ï¼‰

```python
# rag_agent.py

def hybrid_search(
    self,
    user_prompt: str,
    unique_content_id: int,
    top_k: int = 3,
    alpha: float = 0.7
) -> Dict:
    """æ··åˆæª¢ç´¢ï¼šå‘é‡ + å…¨æ–‡æª¢ç´¢"""
    
    # 1. å‘é‡æª¢ç´¢
    vector_results = self._vector_search(
        user_prompt, unique_content_id, top_k * 2
    )
    
    # 2. PostgreSQL å…¨æ–‡æª¢ç´¢
    keyword_results = self._fulltext_search(
        user_prompt, unique_content_id, top_k * 2
    )
    
    # 3. åˆä½µåˆ†æ•¸
    combined = self._merge_scores(
        vector_results, keyword_results, alpha
    )
    
    # 4. å– top-k ä¸¦è£œå…… multimodal_metadata
    top_chunks = combined[:top_k]
    
    # 5. ç‚ºæ¯å€‹ chunk è£œå……åœ–ç‰‡è³‡è¨Š
    enhanced_chunks = []
    for chunk in top_chunks:
        multimodal_meta = chunk.get('multimodal_metadata', {})
        enhanced_chunks.append({
            "chunk_id": chunk['chunk_id'],
            "text": multimodal_meta.get('text_only', chunk['text']),
            "images": multimodal_meta.get('images', []),
            "source_pages": chunk['source_pages']
        })
    
    return {
        "text_chunks": enhanced_chunks,
        "page_content": self._get_page_content(...)
    }
```

#### 5.2 å»ºç«‹å…¨æ–‡æª¢ç´¢ç´¢å¼•

```sql
-- ç‚º chunk_text å»ºç«‹ tsvector ç´¢å¼•
ALTER TABLE document_chunks 
ADD COLUMN search_vector tsvector
GENERATED ALWAYS AS (
    to_tsvector('simple', coalesce(chunk_text, ''))
) STORED;

CREATE INDEX idx_chunks_search 
ON document_chunks USING GIN(search_vector);
```

---

## å¯¦ä½œå„ªå…ˆç´šèˆ‡é æœŸæ•ˆæœ

| Phase | é …ç›® | å·¥ä½œé‡ | é æœŸæ•ˆæœ |
|-------|------|--------|----------|
| 1 | æª”æ¡ˆæ ¼å¼æ¸¬è©¦ | 2-3 å°æ™‚ | ç¢ºä¿æ‰€æœ‰æ ¼å¼å¯ç”¨ |
| 2 | OCR å„ªåŒ– | 4-5 å°æ™‚ | â­â­â­â­ è¾¨è­˜æº–ç¢ºåº¦ +30% |
| 3 | è³‡æ–™æ¸…ç† + å¤šæ¨¡æ…‹ä¿ç•™ | 5-6 å°æ™‚ | â­â­â­â­â­ **é—œéµæ”¹é€²** |
| 4 | èªç¾©åˆ‡åˆ† | 3-4 å°æ™‚ | â­â­â­â­ Chunk å“è³ªæå‡ |
| 5 | Hybrid Search | 4-5 å°æ™‚ | â­â­â­â­ æª¢ç´¢æº–ç¢ºåº¦ +25% |

## é æœŸæˆæœ

### è³‡æ–™å“è³ª
- âœ… OCR æº–ç¢ºåº¦ï¼š70% â†’ **90%+**
- âœ… Chunk æ¸…æ½”åº¦ï¼šåŒ…å«ç¨‹å¼ç¢¼å™ªéŸ³ â†’ **ç´”æ¦‚å¿µæ–‡å­—**
- âœ… å¤šæ¨¡æ…‹ä¿ç•™ï¼šåœ–ç‰‡éºå¤± â†’ **å®Œæ•´ä¿ç•™ base64**

### æª¢ç´¢èˆ‡è©•ä¼°
- âœ… Faithfulness: 0.18 â†’ **0.6-0.8**
- âœ… Answer Relevancy: 0.32 â†’ **0.7-0.9**
- âœ… æª¢ç´¢æº–ç¢ºåº¦ï¼šæå‡ **40%+**

### å¤šæ¨¡æ…‹ LLM æ”¯æ´
- âœ… GPT-4V/Claude 3 å¯ç›´æ¥è®€å–åœ–ç‰‡
- âœ… æ›´ç²¾æº–çš„è¦–è¦ºè³‡è¨Šç†è§£
- âœ… æ¸›å°‘ LLM å¹»è¦ºï¼ˆæœ‰åœ–ç‚ºè­‰ï¼‰

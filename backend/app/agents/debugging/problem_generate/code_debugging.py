import os
import json
from typing import List
from pydantic import BaseModel, Field
from openai import OpenAI

# ================= 1. è¨­å®šèˆ‡å¸¸æ•¸ =================

CONCEPT_DETAILS = {
    'C1': 'è®Šæ•¸èˆ‡è³‡æ–™å‹æ…‹: type(), input(), print(), å­—ä¸²é€£æ¥(+)ã€‚ç¦æ­¢è¿´åœˆèˆ‡åˆ¤æ–·å¼ã€‚',
    'C2': 'æ•¸å€¼èˆ‡å­—ä¸²é‹ç®—: +, -, *, /, //, %, **, slicing, index, len(), find(), count()ã€‚',
    'C3': 'Liståˆ—è¡¨: append, remove, pop, split, join, sort, indexã€‚',
    'C4': 'æ¢ä»¶åˆ¤æ–·: if, elif, else, and, or, notã€‚',
    'C5': 'Forè¿´åœˆ: range, list iteration, break, continueã€‚',
    'C6': 'Whileè¿´åœˆ: while, break, continue, ç„¡çª®è¿´åœˆã€‚',
    'C7': 'Dictionaryå­—å…¸: key-value, get, keys, valuesã€‚',
    'C8': 'Functionå‡½å¼: def, return, global, åƒæ•¸ã€‚'
}

OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
openai_client = OpenAI(api_key=OPENAI_API_KEY)

# ================= 2. Pydantic Schema =================

class Option(BaseModel):
    id: int
    label: str
    feedback: str

class CodeContent(BaseModel):
    content: str

class QuestionContent(BaseModel):
    text: str
    code: CodeContent

class AnswerConfig(BaseModel):
    correct_id: int
    explanation: str

class DebuggingQuestion(BaseModel):
    id: str
    type: str = "debugging"
    targeted_concept: str
    options: List[Option]
    question: QuestionContent
    answer_config: AnswerConfig

class DebuggingQuestionResponse(BaseModel):
    questions: List[DebuggingQuestion]

# ================= 3. AI ç”Ÿæˆé‚è¼¯ =================

def get_unit_from_id(problem_id: str) -> str:
    if "_" in problem_id:
        return problem_id.split("_")[0]
    return "C1"

def generate_debugging_questions(problem_data, problem_id, manual_unit=None):
    if len(problem_data) == 6:
        title, desc, in_desc, out_desc, samples, solution_code = problem_data
    else:
        title, desc, in_desc, out_desc, samples = problem_data[:5]
    
    # Determine concepts
    main_concept = manual_unit if manual_unit else get_unit_from_id(problem_id)
    
    # Construct allowed scope text
    allowed_scope = f"- {main_concept}: {CONCEPT_DETAILS.get(main_concept, '')}"
    if main_concept not in ['C1', 'C2']:
         allowed_scope += f"\n- C1: {CONCEPT_DETAILS['C1']}"
         allowed_scope += f"\n- C2: {CONCEPT_DETAILS['C2']}"

    json_example_str = """
    [
        {
            "id": "Q1",
            "type": "debugging",
            "options": [
                {
                    "id": 1, 
                    "label": "ç¬¬2è¡Œç¨‹å¼æœƒç”¢ç”Ÿå‹æ…‹éŒ¯èª¤ï¼Œå› ç‚ºç„¡æ³•å°‡æ–‡å­—èˆ‡æ•¸å­—ç›´æ¥ç›¸åŠ ", 
                    "feedback": "âœ… æ­£ç¢ºï¼šinput() è®€å…¥çš„æ˜¯å­—ä¸²ï¼Œå¿…é ˆå…ˆè½‰æˆæ•´æ•¸æ‰èƒ½é‹ç®—ã€‚"
                },
                {
                    "id": 2, 
                    "label": "ç¨‹å¼æœƒé †åˆ©åŸ·è¡Œï¼Œä¸¦å°‡æ•¸å­— 5 æ¥åœ¨è¼¸å…¥çš„æ–‡å­—å¾Œé¢", 
                    "feedback": "âŒ éŒ¯èª¤ï¼šPython ä¸å…è¨±å­—ä¸²(str)èˆ‡æ•´æ•¸(int)ç›´æ¥ä½¿ç”¨ + è™Ÿé‹ç®—ã€‚"
                }
            ],
            "question": {
                "code": {
                    "content": "x = input('Enter number: ')\\nprint(x + 5)"
                },
                "text": "è‹¥ä½¿ç”¨è€…è¼¸å…¥ 10ï¼ŒåŸ·è¡Œä¸‹åˆ—ç¨‹å¼ç¢¼æœƒç™¼ç”Ÿä»€éº¼çµæœï¼Ÿ"
            },
            "answer_config": {"correct_id": 1, "explanation": "input() å‡½å¼å›å‚³çš„æ˜¯å­—ä¸²..."}
        }
    ]
    """

    system_prompt = f"""
    ã€è§’è‰²è¨­å®šã€‘ä½ æ˜¯ Python ç¨‹å¼æ•™å­¸å°ˆå®¶ï¼Œå°ˆé–€è¨­è¨ˆã€Œé™¤éŒ¯ (Debugging)ã€è¨“ç·´ã€‚

    ã€æ ¸å¿ƒæ¦‚å¿µã€‘ï¼š{main_concept}
    ã€å…è¨±ä½¿ç”¨çš„èªæ³•ç¯„åœã€‘ï¼š
    {allowed_scope}

    ã€ä»»å‹™ç›®æ¨™ã€‘
    è«‹é‡å°ã€åŸé¡Œè³‡è¨Šã€‘ä¸­çš„æ ¸å¿ƒé‹ç®—é‚è¼¯ï¼Œè¨­è¨ˆä¸€å€‹ã€Œå­ä»»å‹™ã€é™¤éŒ¯é¡Œï¼š
    1. **å­ä»»å‹™æè¿°**ï¼šåœ¨ `question.text` ä¸­èªªæ˜é€™æ®µç¨‹å¼ç¢¼ã€Œé è¨ˆè¦å®Œæˆçš„ä»»å‹™ã€ã€‚
    2. **éŒ¯èª¤ç¨‹å¼ç¢¼**ï¼šåœ¨ `code.content` æä¾›ä¸€æ®µå¸¶æœ‰éŒ¯èª¤(Bug)çš„ç¨‹å¼ç¢¼ï¼Œå°è‡´å…¶ç„¡æ³•å®Œæˆä¸Šè¿°ä»»å‹™ã€‚
    3. **é™¤éŒ¯é¸æ“‡é¡Œ**ï¼šè¨­è¨ˆæœ€å¤š 3 å€‹é¸é …ï¼Œè®“å­¸ç”Ÿæ‰¾å‡ºéŒ¯èª¤åŸå› ã€‚

    ğŸ”¥ ã€çµ•å°é‚è¼¯æ‹†è§£æ©Ÿåˆ¶ã€‘
    1. **å»æƒ…å¢ƒåŒ– (Pure Logic)**ï¼šç¦æ­¢æåŠåŸé¡ŒèƒŒæ™¯ï¼ˆå¦‚ BMIã€é¤è²»ï¼‰ã€‚è®Šæ•¸åå¿…é ˆæŠ½è±¡åŒ–ï¼ˆå¦‚ a, b, res, valï¼‰ã€‚
    2. **é—œéµé‚è¼¯å­é›†**ï¼šç¨‹å¼ç¢¼åƒ…å‘ˆç¾åŸé¡Œæœ€æ ¸å¿ƒçš„ã€Œé‹ç®—é›¶ä»¶ã€ã€‚ä¾‹å¦‚ï¼šåŸé¡Œç®—å¹³å‡ï¼Œå­ä»»å‹™æ‡‰å°ˆæ³¨æ–¼ã€Œç¸½å’Œé™¤ä»¥æ•¸é‡ã€çš„é‚è¼¯ã€‚
    3. **èªæ³•åš´æ ¼é™åˆ¶**ï¼šç”Ÿæˆçš„ç¨‹å¼ç¢¼ **çµ•å°ä¸èƒ½è¶…å‡º** æä¾›çš„èªæ³•ç¯„åœã€‚
    4. **å¿…å®šåŒ…å« Bug**ï¼šç¨‹å¼ç¢¼å¿…é ˆåŒ…å«ä¸€å€‹è©²å–®å…ƒç¨‹åº¦çš„å…¸å‹éŒ¯èª¤ï¼ˆå¦‚å‹æ…‹è½‰æ›å¤±æ•—ã€é‚è¼¯é‹ç®—å­èª¤ç”¨ï¼‰ã€‚
    5. **ç¦æ­¢æ´©é¡Œ**ï¼šé€™æ®µç¨‹å¼ç¢¼ä¸èƒ½æ˜¯åŸé¡Œçš„å®Œæ•´è§£ç­”ã€‚

    ã€ç”Ÿæˆæ­¥é©Ÿã€‘
    1. æå–é‚è¼¯ï¼šåˆ†æåŸé¡Œçš„æ ¸å¿ƒç®—å¼æˆ–è³‡æ–™è™•ç†é»ã€‚
    2. è¨­å®šä»»å‹™ï¼šå°‡è©²é‚è¼¯å¯«æˆä¸€å€‹ç°¡å–®çš„ä»»å‹™ç›®æ¨™ã€‚
    3. æ¤å…¥éŒ¯èª¤ï¼šæ’°å¯«ä¸€æ®µè©¦åœ–é”æˆä»»å‹™ä½†åŒ…å« Bug çš„ç´”æ·¨ç¨‹å¼ç¢¼ã€‚
    4. è¨­è¨ˆé¸é …ï¼šé¸é …æ‡‰é‡å° Bug çš„åŸå› é€²è¡Œè‡ªç„¶èªè¨€æè¿°ã€‚

    ã€è¼¸å‡ºè¦ç¯„ã€‘
    è«‹ç›´æ¥è¼¸å‡º JSON æ ¼å¼ã€‚
    """

    user_prompt = f"""
    ã€åŸå§‹é¡Œç›®è³‡è¨Šã€‘
    ID: {problem_id}
    æ¨™é¡Œï¼š{title}
    æè¿°ï¼š{desc}
    è¼¸å…¥èªªæ˜ï¼š{in_desc}
    è¼¸å‡ºèªªæ˜ï¼š{out_desc}
    ç¯„ä¾‹æ•¸æ“šï¼š{samples}
    """

    try:
        completion = openai_client.beta.chat.completions.parse(
            model="gpt-4o", 
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_prompt},
            ],
            response_format=DebuggingQuestionResponse,
            temperature=0.2,
        )
        parsed_obj = completion.choices[0].message.parsed
        return [q.model_dump() for q in parsed_obj.questions]
    except Exception as e:
        print(f"AI ç”Ÿæˆå¤±æ•—: {e}")
        return None

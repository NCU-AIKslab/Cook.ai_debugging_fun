import asyncio
import json
from dotenv import load_dotenv
from backend.app.agents.teacher_agent.critics.quality_critic import QualityCritic
from backend.app.agents.teacher_agent.skills.exam_generator.exam_nodes import get_llm

load_dotenv()

# Mock RAG context - æ¨¡æ“¬çœŸå¯¦æ•™æå…§å®¹
MOCK_RAG_CONTEXT = """
ç¬¬10é ï¼šè³‡æ–™æ¸…æ´—èˆ‡ç¼ºå¤±å€¼è™•ç†

åœ¨å¯¦éš›çš„è³‡æ–™é›†ä¸­ï¼Œæˆ‘å€‘å¸¸å¸¸æœƒé‡åˆ°ç¼ºå¤±å€¼ï¼ˆMissing Valuesï¼‰çš„å•é¡Œã€‚ä¾‹å¦‚ï¼Œåœ¨ä¸€ä»½åŒ…å«å¹´é½¡ï¼ˆAgeï¼‰ã€æ”¶å…¥ï¼ˆIncomeï¼‰ã€æ•™è‚²ç¨‹åº¦ï¼ˆEducationï¼‰çš„å•å·èª¿æŸ¥è³‡æ–™ä¸­ï¼Œéƒ¨åˆ†å—è¨ªè€…å¯èƒ½æ²’æœ‰å¡«å¯«å¹´é½¡æ¬„ä½ï¼Œå°è‡´è©²æ¬„ä½å‡ºç¾ç©ºç™½ã€‚

è™•ç†ç¼ºå¤±å€¼çš„å¸¸è¦‹æ–¹æ³•åŒ…æ‹¬ï¼š
1. åˆªé™¤æ³•ï¼šç›´æ¥åˆªé™¤åŒ…å«ç¼ºå¤±å€¼çš„æ•´ç­†è³‡æ–™
2. å¡«è£œæ³•ï¼šä½¿ç”¨çµ±è¨ˆå€¼å¡«è£œï¼Œå¦‚å¹³å‡æ•¸ï¼ˆMeanï¼‰ã€ä¸­ä½æ•¸ï¼ˆMedianï¼‰ã€çœ¾æ•¸ï¼ˆModeï¼‰
3. é æ¸¬æ³•ï¼šåˆ©ç”¨å›æ­¸æ¨¡å‹ï¼ˆRegression Modelï¼‰æˆ– KNN ç®—æ³•é æ¸¬ç¼ºå¤±å€¼

åœ¨æˆ‘å€‘çš„ç¯„ä¾‹è³‡æ–™é›†ä¸­ï¼Œå¹´é½¡ï¼ˆAgeï¼‰æ¬„ä½æœ‰ 15% çš„ç¼ºå¤±å€¼ã€‚ç¶“éåˆ†æå¾Œï¼Œæˆ‘å€‘æ±ºå®šä½¿ç”¨ä¸­ä½æ•¸ï¼ˆMedianï¼‰ä¾†å¡«è£œå¹´é½¡çš„ç¼ºå¤±å€¼ï¼Œå› ç‚ºä¸­ä½æ•¸ä¸å—æ¥µç«¯å€¼å½±éŸ¿ï¼Œè¼ƒç‚ºç©©å¥ã€‚

ç¬¬25é ï¼šä¸»æˆåˆ†åˆ†æï¼ˆPCAï¼‰

ä¸»æˆåˆ†åˆ†æï¼ˆPrincipal Component Analysis, PCAï¼‰æ˜¯ä¸€ç¨®å¸¸ç”¨çš„é™ç¶­æŠ€è¡“ã€‚ç•¶è³‡æ–™é›†åŒ…å«éå¤šç‰¹å¾µæ™‚ï¼ˆä¾‹å¦‚ 100 å€‹ç‰¹å¾µï¼‰ï¼ŒPCA å¯ä»¥å°‡é€™äº›ç‰¹å¾µå£“ç¸®æˆè¼ƒå°‘çš„ä¸»è¦æˆåˆ†ï¼ˆä¾‹å¦‚ 3-5 å€‹ï¼‰ï¼ŒåŒæ™‚ä¿ç•™å¤§éƒ¨åˆ†çš„è³‡è¨Šã€‚

PCA çš„ä¸»è¦ç›®çš„ï¼š
- é™ä½è³‡æ–™ç¶­åº¦ï¼Œç°¡åŒ–å¾ŒçºŒåˆ†æ
- å»é™¤ç‰¹å¾µé–“çš„ç›¸é—œæ€§
- ä¾¿æ–¼è³‡æ–™è¦–è¦ºåŒ–

ç¯„ä¾‹ï¼šåœ¨ä¸€å€‹æˆ¿åƒ¹é æ¸¬å°ˆæ¡ˆä¸­ï¼Œæˆ‘å€‘åŸæœ¬æœ‰ 20 å€‹ç‰¹å¾µï¼ˆåªæ•¸ã€æˆ¿é–“æ•¸ã€å±‹é½¡ç­‰ï¼‰ï¼Œä½¿ç”¨ PCA é™ç¶­åˆ° 2 å€‹ä¸»è¦æˆåˆ†å¾Œï¼Œå¯ä»¥æ›´å®¹æ˜“åœ°å°‡è³‡æ–™ç¹ªè£½æˆäºŒç¶­æ•£ä½ˆåœ–ã€‚
"""

async def test_new_rubric_structure():
    """
    Test new rubric structure with mock RAG context.
    Tests all 4 criteria: Understandable, Grammatical, Logical_Consistency, Phrasing
    """
    print("=== Testing New Rubric Structure with Mock RAG Context ===\n")
    
    llm = get_llm()
    critic = QualityCritic(llm, threshold=4.0)
    
    # Test Case 1: Missing Context (Understandable issue)
    print("Test Case 1: ç¼ºä¹æƒ…å¢ƒèªªæ˜ (Understandable)")
    print("=" * 70)
    
    missing_context_case = {
        "type": "multiple_choice",
        "questions": [{
            "question_number": 6,
            "question_text": "å°æ–¼è–ªæ°´çš„å¡«è£œï¼Œé€šå¸¸ä½¿ç”¨ä»€éº¼å€¼ï¼Ÿ",
            "options": {
                "A": "æœ€å¤§å€¼",
                "B": "æœ€å°å€¼",
                "C": "å¹³å‡å€¼",
                "D": "ä¸­ä½æ•¸"
            },
            "correct_answer": "D",
            "source": {
                "page_number": "13",
                "evidence": "è–ªæ°´ (Salary) åˆ—å¡«è£œç‚ºä¸­ä½æ•¸ã€‚"
            },
            "rag_context": MOCK_RAG_CONTEXT  # åŠ å…¥ RAG context
        }]
    }
    
    print(f"é¡Œç›®: {missing_context_case['questions'][0]['question_text']}")
    print(f"å•é¡Œåˆ†æ:")
    print(f"  1. ç¼ºä¹ã€Œç‚ºä»€éº¼è–ªæ°´éœ€è¦å¡«è£œã€çš„èƒŒæ™¯ï¼ˆè³‡æ–™æœ‰ç¼ºå¤±å€¼ï¼‰")
    print(f"  2. ç¼ºä¹ã€Œç‚ºä»€éº¼é¸æ“‡ä¸­ä½æ•¸ã€çš„ç†ç”±ï¼ˆè–ªæ°´æœ‰æ¥µç«¯å€¼ï¼‰")
    print(f"  3. ã€Œé€šå¸¸ã€ä¸€è©æ¨¡ç³Šä¸æ¸…")
    print(f"  4. å­¸ç”Ÿç„¡æ³•ç†è§£é¡Œç›®çš„æƒ…å¢ƒå’Œç›®çš„\n")
    
    result1 = await critic.evaluate(missing_context_case, criteria=["Understandable"])
    
    if "evaluations" in result1:
        for eval_item in result1["evaluations"]:
            print(f"ğŸ“Š è©•åˆ†: {eval_item['rating']}/5 (é æœŸ 2-3 åˆ†)")
            print(f"åˆ†æ: {eval_item['analysis'][:250]}...")
            if eval_item.get('suggestions'):
                print(f"\nå»ºè­°: {len(eval_item['suggestions'])} é …")
                for i, sug in enumerate(eval_item['suggestions'][:3], 1):
                    print(f"  {i}. {sug}")
    
    # Test Case 2: Answer Contradiction (Logical_Consistency issue)
    print("\n\n" + "=" * 70)
    print("Test Case 2: ç­”æ¡ˆèˆ‡åƒè€ƒè³‡æ–™çŸ›ç›¾ (Logical_Consistency)")
    print("=" * 70)
    
    contradiction_case = {
        "type": "multiple_choice",
        "questions": [{
            "question_number": 1,
            "question_text": "åœ¨ç¯„ä¾‹è³‡æ–™é›†ä¸­ï¼Œå¡«è£œå¹´é½¡ç¼ºå¤±å€¼ä½¿ç”¨çš„æ–¹æ³•ç‚ºä½•ï¼Ÿ",
            "options": {
                "A": "ä¸­ä½æ•¸",
                "B": "å¹³å‡æ•¸",
                "C": "çœ¾æ•¸",
                "D": "å›æ­¸æ¨¡å‹"
            },
            "correct_answer": "B",  # éŒ¯èª¤ï¼æ‡‰è©²æ˜¯ A
            "source": {
                " number": "10",
                "evidence": "æˆ‘å€‘æ±ºå®šä½¿ç”¨ä¸­ä½æ•¸ï¼ˆMedianï¼‰ä¾†å¡«è£œå¹´é½¡çš„ç¼ºå¤±å€¼ã€‚"
            },
            "rag_context": MOCK_RAG_CONTEXT
        }]
    }
    
    print(f"é¡Œç›®: {contradiction_case['questions'][0]['question_text']}")
    print(f"æ­£ç¢ºç­”æ¡ˆ: B (å¹³å‡æ•¸)")
    print(f"Evidence: ä½¿ç”¨ä¸­ä½æ•¸å¡«è£œ")
    print(f"â†’ çŸ›ç›¾ï¼\n")
    
    result2 = await critic.evaluate(contradiction_case, criteria=["Logical_Consistency"])
    
    if "evaluations" in result2:
        for eval_item in result2["evaluations"]:
            print(f"ğŸ“Š è©•åˆ†: {eval_item['rating']}/5 (é æœŸ 1 åˆ†)")
            print(f"åˆ†æ: {eval_item['analysis'][:200]}...")
            if eval_item.get('suggestions'):
                print(f"\nå»ºè­°:")
                for sug in eval_item['suggestions'][:2]:
                    print(f"  - {sug}")
    
    # Test Case 3: Spelling Error (Grammatical issue)
    print("\n\n" + "=" * 70)
    print("Test Case 3: å°ˆæ¥­è¡“èªæ‹¼å¯«éŒ¯èª¤ (Grammatical)")
    print("=" * 70)
    
    spelling_error_case = {
        "type": "multiple_choice",
        "questions": [{
            "question_number": 1,
            "question_text": "Pæ–½é™ç¶­çš„ä¸»è¦ç›®çš„ç‚ºä½•ï¼Ÿ",
            "options": {
                "A": "å¢åŠ ç‰¹å¾µæ•¸é‡",
                "B": "é™ä½è³‡æ–™ç¶­åº¦",
                "C": "å¡«è£œç¼ºå¤±å€¼",
                "D": "ç§»é™¤ç•°å¸¸å€¼"
            },
            "correct_answer": "B",
            "source": {
                "page_number": "25",
                "evidence": "PCA çš„ä¸»è¦ç›®çš„ï¼šé™ä½è³‡æ–™ç¶­åº¦"
            },
            "rag_context": MOCK_RAG_CONTEXT
        }]
    }
    
    print(f"é¡Œç›®: {spelling_error_case['questions'][0]['question_text']}")
    print(f"éŒ¯èª¤: ã€ŒPæ–½ã€æ‡‰ç‚ºã€ŒPCAã€\n")
    
    result3 = await critic.evaluate(spelling_error_case, criteria=["Grammatical"])
    
    if "evaluations" in result3:
        for eval_item in result3["evaluations"]:
            print(f"ğŸ“Š è©•åˆ†: {eval_item['rating']}/5 (é æœŸ 1-2 åˆ†)")
            print(f"åˆ†æ: {eval_item['analysis'][:150]}...")
    
    # Test Case 4: Mainland Chinese Terms (Phrasing issue)
    print("\n\n" + "=" * 70)
    print("Test Case 4: å¤§é™¸ç”¨èª (Phrasing)")
    print("=" * 70)
    
    mainland_terms_case = {
        "type": "multiple_choice",
        "questions": [{
            "question_number": 1,
            "question_text": "åœ¨æœºå™¨å­¦ä¹ ä¸­ï¼Œæ•°æ®æ¸…æ´—çš„ä¸»è¦ç›®çš„æ˜¯ä»€ä¹ˆï¼Ÿ",
            "options": {
                "A": "æé«˜æ•°æ®è´¨é‡",
                "B": "å‡å°‘æ•°æ®é‡",
                "C": "å¢åŠ ç‰¹å¾",
                "D": "åˆ é™¤æ‰€æœ‰ç¼ºå¤±å€¼"
            },
            "correct_answer": "A",
            "source": {
                "page_number": "10",
                "evidence": "è³‡æ–™æ¸…æ´—çš„ç›®çš„æ˜¯æé«˜è³‡æ–™å“è³ªã€‚"
            },
            "rag_context": MOCK_RAG_CONTEXT
        }]
    }
    
    print(f"é¡Œç›®: {mainland_terms_case['questions'][0]['question_text']}")
    print(f"å•é¡Œ: ã€Œæœºå™¨å­¦ä¹ ã€â†’ã€Œæ©Ÿå™¨å­¸ç¿’ã€ã€ã€Œæ•°æ®ã€â†’ã€Œè³‡æ–™ã€ã€ã€Œè´¨é‡ã€â†’ã€Œå“è³ªã€\n")
    
    result4 = await critic.evaluate(mainland_terms_case, criteria=["Phrasing"])
    
    if "evaluations" in result4:
        for eval_item in result4["evaluations"]:
            print(f"ğŸ“Š è©•åˆ†: {eval_item['rating']}/5 (é æœŸ 1-2 åˆ†)")
            print(f"åˆ†æ: {eval_item['analysis'][:200]}...")
            if eval_item.get('suggestions'):
                print(f"\nå»ºè­°: {len(eval_item['suggestions'])} é …")
    
    print("\n" + "=" * 70)
    print("âœ… æ–° Rubric çµæ§‹æ¸¬è©¦å®Œæˆ")
    print("=" * 70)

if __name__ == "__main__":
    asyncio.run(test_new_rubric_structure())
